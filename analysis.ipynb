{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Replace 'your_file.xlsx' with the actual file path\n",
    "file_path = 'data/kpmg.xlsx'\n",
    "\n",
    "# Use the ExcelFile class to read the Excel file\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# List the sheet names in the Excel file\n",
    "sheet_names = xls.sheet_names\n",
    "\n",
    "# Create DataFrames for each sheet\n",
    "dataframes = {}  # Dictionary to store DataFrames\n",
    "\n",
    "for sheet_name in sheet_names:\n",
    "    dataframes[sheet_name] = pd.read_excel(xls, sheet_name)\n",
    "\n",
    "# Now you have separate DataFrames for each sheet\n",
    "# access the dataframes using their sheet names\n",
    "transaction_data = dataframes['Transactions']\n",
    "demographic_data = dataframes['CustomerDemographic']\n",
    "customer_data = dataframes['CustomerAddress']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>address</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>property_valuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>060 Morning Avenue</td>\n",
       "      <td>2016</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6 Meadow Vale Court</td>\n",
       "      <td>2153</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0 Holy Cross Court</td>\n",
       "      <td>4211</td>\n",
       "      <td>QLD</td>\n",
       "      <td>Australia</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>17979 Del Mar Point</td>\n",
       "      <td>2448</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>9 Oakridge Court</td>\n",
       "      <td>3216</td>\n",
       "      <td>VIC</td>\n",
       "      <td>Australia</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id              address  postcode            state    country  \\\n",
       "0            1   060 Morning Avenue      2016  New South Wales  Australia   \n",
       "1            2  6 Meadow Vale Court      2153  New South Wales  Australia   \n",
       "2            4   0 Holy Cross Court      4211              QLD  Australia   \n",
       "3            5  17979 Del Mar Point      2448  New South Wales  Australia   \n",
       "4            6     9 Oakridge Court      3216              VIC  Australia   \n",
       "\n",
       "   property_valuation  \n",
       "0                  10  \n",
       "1                  10  \n",
       "2                   9  \n",
       "3                   4  \n",
       "4                   9  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the first five rows of the customer dataset\n",
    "customer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>past_3_years_bike_related_purchases</th>\n",
       "      <th>DOB</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_industry_category</th>\n",
       "      <th>wealth_segment</th>\n",
       "      <th>deceased_indicator</th>\n",
       "      <th>default</th>\n",
       "      <th>owns_car</th>\n",
       "      <th>tenure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Laraine</td>\n",
       "      <td>Medendorp</td>\n",
       "      <td>F</td>\n",
       "      <td>93</td>\n",
       "      <td>1953-10-12</td>\n",
       "      <td>Executive Secretary</td>\n",
       "      <td>Health</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>\"'</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Eli</td>\n",
       "      <td>Bockman</td>\n",
       "      <td>Male</td>\n",
       "      <td>81</td>\n",
       "      <td>1980-12-16</td>\n",
       "      <td>Administrative Officer</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>&lt;script&gt;alert('hi')&lt;/script&gt;</td>\n",
       "      <td>Yes</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Arlin</td>\n",
       "      <td>Dearle</td>\n",
       "      <td>Male</td>\n",
       "      <td>61</td>\n",
       "      <td>1954-01-20</td>\n",
       "      <td>Recruiting Manager</td>\n",
       "      <td>Property</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>2018-02-01 00:00:00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Talbot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>1961-10-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IT</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>() { _; } &gt;_[$($())] { touch /tmp/blns.shellsh...</td>\n",
       "      <td>No</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Sheila-kathryn</td>\n",
       "      <td>Calton</td>\n",
       "      <td>Female</td>\n",
       "      <td>56</td>\n",
       "      <td>1977-05-13</td>\n",
       "      <td>Senior Editor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Affluent Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>NIL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id      first_name  last_name  gender  \\\n",
       "0            1         Laraine  Medendorp       F   \n",
       "1            2             Eli    Bockman    Male   \n",
       "2            3           Arlin     Dearle    Male   \n",
       "3            4          Talbot        NaN    Male   \n",
       "4            5  Sheila-kathryn     Calton  Female   \n",
       "\n",
       "   past_3_years_bike_related_purchases        DOB               job_title  \\\n",
       "0                                   93 1953-10-12     Executive Secretary   \n",
       "1                                   81 1980-12-16  Administrative Officer   \n",
       "2                                   61 1954-01-20      Recruiting Manager   \n",
       "3                                   33 1961-10-03                     NaN   \n",
       "4                                   56 1977-05-13           Senior Editor   \n",
       "\n",
       "  job_industry_category     wealth_segment deceased_indicator  \\\n",
       "0                Health      Mass Customer                  N   \n",
       "1    Financial Services      Mass Customer                  N   \n",
       "2              Property      Mass Customer                  N   \n",
       "3                    IT      Mass Customer                  N   \n",
       "4                   NaN  Affluent Customer                  N   \n",
       "\n",
       "                                             default owns_car  tenure  \n",
       "0                                                 \"'      Yes    11.0  \n",
       "1                       <script>alert('hi')</script>      Yes    16.0  \n",
       "2                                2018-02-01 00:00:00      Yes    15.0  \n",
       "3  () { _; } >_[$($())] { touch /tmp/blns.shellsh...       No     7.0  \n",
       "4                                                NIL      Yes     8.0  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the first five rows of the demographic dataset\n",
    "demographic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Gender Values:\n",
      "['F' 'Male' 'Female' 'U' 'Femal' 'M']\n",
      "\n",
      "Gender Value Counts:\n",
      "Female    2037\n",
      "Male      1872\n",
      "U           88\n",
      "F            1\n",
      "Femal        1\n",
      "M            1\n",
      "Name: gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get unique values in the 'gender' column and count the occurrences of each unique value\n",
    "gender_counts = demographic_data['gender'].unique()\n",
    "counts = demographic_data['gender'].value_counts()\n",
    "\n",
    "# Print the unique values and their respective counts\n",
    "print(\"Unique Gender Values:\")\n",
    "print(gender_counts)\n",
    "print(\"\\nGender Value Counts:\")\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Gender Values (Corrected):\n",
      "['Female' 'Male' 'Unspecified']\n",
      "\n",
      "Gender Value Counts (Corrected):\n",
      "Female         2039\n",
      "Male           1873\n",
      "Unspecified      88\n",
      "Name: gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping dictionary to standardize gender values\n",
    "gender_mapping = {\n",
    "    'F': 'Female',\n",
    "    'Male': 'Male',\n",
    "    'Female': 'Female',\n",
    "    'U': 'Unspecified',\n",
    "    'Femal': 'Female',\n",
    "    'M': 'Male'\n",
    "}\n",
    "\n",
    "# Use the mapping dictionary to replace gender values\n",
    "demographic_data['gender'] = demographic_data['gender'].replace(gender_mapping)\n",
    "\n",
    "# Check the corrected unique values and their counts\n",
    "gender_counts_corrected = demographic_data['gender'].unique()\n",
    "counts_corrected = demographic_data['gender'].value_counts()\n",
    "\n",
    "# Print the corrected unique values and their counts\n",
    "print(\"Unique Gender Values (Corrected):\")\n",
    "print(gender_counts_corrected)\n",
    "print(\"\\nGender Value Counts (Corrected):\")\n",
    "print(counts_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>online_order</th>\n",
       "      <th>order_status</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_line</th>\n",
       "      <th>product_class</th>\n",
       "      <th>product_size</th>\n",
       "      <th>list_price</th>\n",
       "      <th>standard_cost</th>\n",
       "      <th>product_first_sold_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2950</td>\n",
       "      <td>2017-02-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Solex</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>71.49</td>\n",
       "      <td>53.62</td>\n",
       "      <td>41245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3120</td>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Trek Bicycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>large</td>\n",
       "      <td>2091.47</td>\n",
       "      <td>388.92</td>\n",
       "      <td>41701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>402</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>OHM Cycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>1793.43</td>\n",
       "      <td>248.82</td>\n",
       "      <td>36361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>3135</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Norco Bicycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>1198.46</td>\n",
       "      <td>381.10</td>\n",
       "      <td>36145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>787</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Giant Bicycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>large</td>\n",
       "      <td>1765.30</td>\n",
       "      <td>709.48</td>\n",
       "      <td>42226.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id  product_id  customer_id transaction_date  online_order  \\\n",
       "0               1           2         2950       2017-02-25           0.0   \n",
       "1               2           3         3120       2017-05-21           1.0   \n",
       "2               3          37          402       2017-10-16           0.0   \n",
       "3               4          88         3135       2017-08-31           0.0   \n",
       "4               5          78          787       2017-10-01           1.0   \n",
       "\n",
       "  order_status           brand product_line product_class product_size  \\\n",
       "0     Approved           Solex     Standard        medium       medium   \n",
       "1     Approved   Trek Bicycles     Standard        medium        large   \n",
       "2     Approved      OHM Cycles     Standard           low       medium   \n",
       "3     Approved  Norco Bicycles     Standard        medium       medium   \n",
       "4     Approved  Giant Bicycles     Standard        medium        large   \n",
       "\n",
       "   list_price  standard_cost  product_first_sold_date  \n",
       "0       71.49          53.62                  41245.0  \n",
       "1     2091.47         388.92                  41701.0  \n",
       "2     1793.43         248.82                  36361.0  \n",
       "3     1198.46         381.10                  36145.0  \n",
       "4     1765.30         709.48                  42226.0  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the first five rows of the transaction dataset\n",
    "transaction_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy and Completeness Assessment\n",
    "\n",
    "***Check for data accuracy issues, such as missing values in critical columns.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**customer Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3999 entries, 0 to 3998\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   customer_id         3999 non-null   int64 \n",
      " 1   address             3999 non-null   object\n",
      " 2   postcode            3999 non-null   int64 \n",
      " 3   state               3999 non-null   object\n",
      " 4   country             3999 non-null   object\n",
      " 5   property_valuation  3999 non-null   int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 187.6+ KB\n"
     ]
    }
   ],
   "source": [
    "customer_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Missing Values in Transaction Dataset************\n",
      "customer_id           0\n",
      "address               0\n",
      "postcode              0\n",
      "state                 0\n",
      "country               0\n",
      "property_valuation    0\n",
      "dtype: int64\n",
      "\n",
      "Percentage of Missing Values:\n",
      "customer_id           0.0\n",
      "address               0.0\n",
      "postcode              0.0\n",
      "state                 0.0\n",
      "country               0.0\n",
      "property_valuation    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Assessment\n",
    "import numpy as np\n",
    "# Check for missing values in key columns\n",
    "missing_values =customer_data.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of missing values in each column\n",
    "total_records = customer_data.shape[0]\n",
    "percentage_missing = (missing_values / total_records) * 100\n",
    "\n",
    "# Print results\n",
    "print(np.char.center('Missing Values in Transaction Dataset', 60, '*'))\n",
    "print(missing_values)\n",
    "print(\"\\nPercentage of Missing Values:\")\n",
    "print(percentage_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3999.000000\n",
       "mean        7.514379\n",
       "std         2.824663\n",
       "min         1.000000\n",
       "25%         6.000000\n",
       "50%         8.000000\n",
       "75%        10.000000\n",
       "max        12.000000\n",
       "Name: property_valuation, dtype: float64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_data['property_valuation'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows in Transaction Dataset:\n",
      "Empty DataFrame\n",
      "Columns: [customer_id, address, postcode, state, country, property_valuation]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "duplicate_rows = customer_data[customer_data.duplicated()]\n",
    "# Print duplicate rows, if any\n",
    "print(\"Duplicate Rows in Transaction Dataset:\")\n",
    "print(duplicate_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `country` column in the 'customer_data' dataset contains the value \"Australia\" for all its entries. Since this column doesn't provide any additional information due to its uniformity (as it's the same for all records), we can safely remove it without losing any valuable data. This can help make your dataset more concise and easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data.drop('country', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demographic_data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                               Non-Null Count  Dtype         \n",
      "---  ------                               --------------  -----         \n",
      " 0   customer_id                          4000 non-null   int64         \n",
      " 1   first_name                           4000 non-null   object        \n",
      " 2   last_name                            3875 non-null   object        \n",
      " 3   gender                               4000 non-null   object        \n",
      " 4   past_3_years_bike_related_purchases  4000 non-null   int64         \n",
      " 5   DOB                                  3913 non-null   datetime64[ns]\n",
      " 6   job_title                            3494 non-null   object        \n",
      " 7   job_industry_category                3344 non-null   object        \n",
      " 8   wealth_segment                       4000 non-null   object        \n",
      " 9   deceased_indicator                   4000 non-null   object        \n",
      " 10  default                              3698 non-null   object        \n",
      " 11  owns_car                             4000 non-null   object        \n",
      " 12  tenure                               3913 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(9)\n",
      "memory usage: 406.4+ KB\n"
     ]
    }
   ],
   "source": [
    "demographic_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Missing Values in Demographic Dataset************\n",
      "customer_id                              0\n",
      "first_name                               0\n",
      "last_name                              125\n",
      "gender                                   0\n",
      "past_3_years_bike_related_purchases      0\n",
      "DOB                                     87\n",
      "job_title                              506\n",
      "job_industry_category                  656\n",
      "wealth_segment                           0\n",
      "deceased_indicator                       0\n",
      "default                                302\n",
      "owns_car                                 0\n",
      "tenure                                  87\n",
      "dtype: int64\n",
      "\n",
      "Percentage of Missing Values:\n",
      "customer_id                             0.000\n",
      "first_name                              0.000\n",
      "last_name                               3.125\n",
      "gender                                  0.000\n",
      "past_3_years_bike_related_purchases     0.000\n",
      "DOB                                     2.175\n",
      "job_title                              12.650\n",
      "job_industry_category                  16.400\n",
      "wealth_segment                          0.000\n",
      "deceased_indicator                      0.000\n",
      "default                                 7.550\n",
      "owns_car                                0.000\n",
      "tenure                                  2.175\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in key columns\n",
    "missing_values = demographic_data.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of missing values in each column\n",
    "total_records = demographic_data.shape[0]\n",
    "percentage_missing = (missing_values / total_records) * 100\n",
    "\n",
    "# Print results\n",
    "print(np.char.center('Missing Values in Demographic Dataset', 60, '*'))\n",
    "print(missing_values)\n",
    "print(\"\\nPercentage of Missing Values:\")\n",
    "print(percentage_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`last_name:` This column has a relatively low percentage of missing values, about 3.1%. It's reasonable to fill the missing values with the mode, which means replacing them with the most frequently occurring last name in the dataset. This approach helps maintain data integrity.\n",
    "\n",
    "`DOB (Date of Birth):` The 'DOB' column has around 2.2% missing values. Given the importance of this information, it's advisable to fill the missing values with the mode, which is the most common date of birth in the dataset. This way, you can preserve the completeness of the data.\n",
    "\n",
    "`job_title:` The 'job_title' column has a higher percentage of missing values, approximately 12.6%. In this case, filling the missing values with the mode is a practical solution. It ensures that the most common job titles are used to complete the dataset, even though it may not be ideal for all cases.\n",
    "\n",
    "`job_industry_category:` With about 16.4% missing values, the 'job_industry_category' column requires filling. Again, using the mode to replace missing values is a reasonable choice. This method ensures that the most prevalent industry categories are used for the missing entries.\n",
    "\n",
    "`default:` The 'default' column has a relatively high percentage of missing values, around 7.6%. Filling these missing values with the mode is a suitable approach, making use of the most common default status. However, be aware that this method might not capture the complexity of individual default preferences.\n",
    "\n",
    "`Tenure:` The 'tenure' column has approximately 2.2% missing values. Filling these missing values with the mean of the 'tenure' values is a practical solution. Using the mean allows you to maintain data continuity and helps provide an estimate for missing values based on the existing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with mode for categorical columns\n",
    "demographic_data['last_name'] = demographic_data['last_name'].fillna(demographic_data['last_name'].mode()[0])\n",
    "demographic_data['DOB'] = demographic_data['DOB'].fillna(demographic_data['DOB'].mode()[0])\n",
    "demographic_data['job_title'] = demographic_data['job_title'].fillna(demographic_data['job_title'].mode()[0])\n",
    "demographic_data['job_industry_category'] = demographic_data['job_industry_category'].fillna(demographic_data['job_industry_category'].mode()[0])\n",
    "demographic_data['default'] = demographic_data['default'].fillna(demographic_data['default'].mode()[0])\n",
    "\n",
    "# Fill missing values in 'tenure' column with the mean\n",
    "demographic_data['tenure'] = demographic_data['tenure'].fillna(demographic_data['tenure'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to the desired data types\n",
    "demographic_data['past_3_years_bike_related_purchases'] = pd.to_numeric(demographic_data['past_3_years_bike_related_purchases'])\n",
    "demographic_data['tenure'] = pd.to_numeric(demographic_data['tenure'])\n",
    "demographic_data['DOB'] = pd.to_datetime(demographic_data['DOB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in the dataset\n",
    "duplicates = demographic_data[demographic_data.duplicated()]\n",
    "\n",
    "# Print the duplicated rows, if any\n",
    "if not duplicates.empty:\n",
    "    print(\"Duplicated Rows:\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"No duplicates found in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first_name',\n",
       " 'last_name',\n",
       " 'gender',\n",
       " 'job_title',\n",
       " 'job_industry_category',\n",
       " 'wealth_segment',\n",
       " 'deceased_indicator',\n",
       " 'default',\n",
       " 'owns_car']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collecting the categorical columns into a list\n",
    "cat_col = demographic_data.select_dtypes(include=['object']).columns.tolist()\n",
    "cat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_name:\n",
      "['Laraine' 'Eli' 'Arlin' ... 'Stephie' 'Rusty' 'Sarene']\n",
      "*******\n",
      "last_name:\n",
      "['Medendorp' 'Bockman' 'Dearle' ... 'Halgarth' 'Woolley' 'Oldland']\n",
      "*******\n",
      "gender:\n",
      "['Female' 'Male' 'Unspecified']\n",
      "*******\n",
      "job_title:\n",
      "['Executive Secretary' 'Administrative Officer' 'Recruiting Manager'\n",
      " 'Business Systems Development Analyst' 'Senior Editor' 'Media Manager I'\n",
      " 'Senior Quality Engineer' 'Nuclear Power Engineer' 'Developer I'\n",
      " 'Account Executive' 'Junior Executive' 'Media Manager IV'\n",
      " 'Sales Associate' 'Professor' 'Geological Engineer' 'Project Manager'\n",
      " 'Safety Technician I' 'Research Assistant I' 'Accounting Assistant III'\n",
      " 'Editor' 'Research Nurse' 'Safety Technician III' 'Staff Accountant III'\n",
      " 'Legal Assistant' 'Product Engineer' 'Information Systems Manager'\n",
      " 'VP Quality Control' 'Social Worker' 'Senior Cost Accountant'\n",
      " 'Assistant Media Planner' 'Payment Adjustment Coordinator' 'Food Chemist'\n",
      " 'Accountant III' 'Director of Sales' 'Senior Financial Analyst'\n",
      " 'Registered Nurse' 'Biostatistician II' 'Computer Systems Analyst II'\n",
      " 'Software Test Engineer II' 'Paralegal' 'VP Sales'\n",
      " 'Chief Design Engineer' 'Office Assistant III'\n",
      " 'Physical Therapy Assistant' 'Help Desk Operator' 'Web Developer II'\n",
      " 'Research Associate' 'Teacher' 'VP Product Management' 'Statistician II'\n",
      " 'Automation Specialist IV' 'Data Coordiator' 'Software Test Engineer III'\n",
      " 'Internal Auditor' 'Analyst Programmer' 'Occupational Therapist'\n",
      " 'Speech Pathologist' 'Quality Control Specialist' 'Civil Engineer'\n",
      " 'Software Engineer III' 'Community Outreach Specialist'\n",
      " 'Safety Technician IV' 'VP Accounting' 'General Manager'\n",
      " 'Nurse Practicioner' 'Automation Specialist II' 'Marketing Assistant'\n",
      " 'Marketing Manager' 'Staff Scientist' 'Assistant Professor'\n",
      " 'Budget/Accounting Analyst IV' 'Associate Professor' 'Graphic Designer'\n",
      " 'Administrative Assistant II' 'Compensation Analyst'\n",
      " 'Systems Administrator III' 'Financial Advisor' 'Chemical Engineer'\n",
      " 'Web Designer I' 'Senior Developer' 'Office Assistant II' 'Recruiter'\n",
      " 'Operator' 'Programmer Analyst III' 'Quality Engineer'\n",
      " 'Environmental Tech' 'Analog Circuit Design manager' 'Cost Accountant'\n",
      " 'Librarian' 'Structural Analysis Engineer' 'Pharmacist'\n",
      " 'Assistant Manager' 'Accountant I' 'Web Designer III' 'Geologist III'\n",
      " 'Software Test Engineer I' 'Structural Engineer' 'Safety Technician II'\n",
      " 'Web Developer III' 'Programmer Analyst II' 'Design Engineer'\n",
      " 'Statistician I' 'VP Marketing' 'Desktop Support Technician' 'Actuary'\n",
      " 'Database Administrator III' 'Electrical Engineer' 'Tax Accountant'\n",
      " 'Clinical Specialist' 'Database Administrator IV'\n",
      " 'Systems Administrator II' 'Account Coordinator' 'Programmer III'\n",
      " 'Administrative Assistant III' 'Nurse' 'Technical Writer'\n",
      " 'Staff Accountant II' 'Dental Hygienist' 'Sales Representative'\n",
      " 'Budget/Accounting Analyst III' 'Computer Systems Analyst IV'\n",
      " 'Geologist I' 'Financial Analyst' 'Accounting Assistant II'\n",
      " 'Senior Sales Associate' 'Database Administrator II' 'Engineer I'\n",
      " 'Budget/Accounting Analyst I' 'Developer IV' 'Database Administrator I'\n",
      " 'Environmental Specialist' 'Computer Systems Analyst I'\n",
      " 'Account Representative IV' 'Statistician IV' 'Human Resources Manager'\n",
      " 'GIS Technical Architect' 'Programmer IV' 'Accounting Assistant IV'\n",
      " 'Software Engineer IV' 'Programmer II' 'Engineer III'\n",
      " 'Software Consultant' 'Biostatistician IV' 'Help Desk Technician'\n",
      " 'Automation Specialist I' 'Developer III' 'Human Resources Assistant I'\n",
      " 'Geologist IV' 'Media Manager II' 'Statistician III' 'Engineer II'\n",
      " 'Health Coach II' 'Developer II' 'Systems Administrator I'\n",
      " 'Web Developer I' 'Software Engineer II' 'Accounting Assistant I'\n",
      " 'Research Assistant II' 'Programmer Analyst IV' 'Health Coach I'\n",
      " 'Accountant II' 'Automation Specialist III' 'Administrative Assistant I'\n",
      " 'Health Coach IV' 'Media Manager III' 'Account Representative III'\n",
      " 'Web Designer IV' 'Budget/Accounting Analyst II' 'Web Developer IV'\n",
      " 'Programmer I' 'Biostatistician III' 'Software Test Engineer IV'\n",
      " 'Research Assistant IV' 'Account Representative I' 'Accountant IV'\n",
      " 'Biostatistician I' 'Human Resources Assistant IV'\n",
      " 'Administrative Assistant IV' 'Office Assistant I'\n",
      " 'Human Resources Assistant II' 'Mechanical Systems Engineer'\n",
      " 'Engineer IV' 'Health Coach III' 'Office Assistant IV'\n",
      " 'Software Engineer I' 'Human Resources Assistant III'\n",
      " 'Staff Accountant I' 'Computer Systems Analyst III' 'Geologist II'\n",
      " 'Web Designer II' 'Staff Accountant IV' 'Account Representative II'\n",
      " 'Programmer Analyst I' 'Systems Administrator IV'\n",
      " 'Research Assistant III']\n",
      "*******\n",
      "job_industry_category:\n",
      "['Health' 'Financial Services' 'Property' 'IT' 'Manufacturing' 'Retail'\n",
      " 'Argiculture' 'Telecommunications' 'Entertainment']\n",
      "*******\n",
      "wealth_segment:\n",
      "['Mass Customer' 'Affluent Customer' 'High Net Worth']\n",
      "*******\n",
      "deceased_indicator:\n",
      "['N' 'Y']\n",
      "*******\n",
      "default:\n",
      "['\"\\'' \"<script>alert('hi')</script>\" datetime.datetime(2018, 2, 1, 0, 0)\n",
      " '() { _; } >_[$($())] { touch /tmp/blns.shellshock2.fail; }' 'NIL'\n",
      " 'ðµ ð ð ð' 'â°â´âµâââ' '(â¯Â°â¡Â°ï¼â¯ï¸µ â»ââ»)' '0/0' 'ð©ð½'\n",
      " 'ÅâÂ´Â®â\\xa0Â¥Â¨ËÃ¸Ïââ' 'nil' -100 'â°â´âµ' 'ð'\n",
      " 1000000000000000049861653971908893017010268485438462151574892930611988399099305815384459015356416\n",
      " 'ï¾ï½¥â¿ã¾â²(ï½¡ââ¿âï½¡)â±â¿ï½¥ï¾' 'Î©âÃ§ââ«ËÂµâ¤â¥Ã·' 'ÅâÂ´â°ËÃÂ¨ËÃâââ'\n",
      " 'ï¼ï¼ï¼' '../../../../../../../../../../../etc/hosts'\n",
      " '×Ö¸×Ö°×ªÖ¸×testØ§ÙØµÙØ\\xadØ§Øª Ø§ÙØªÙØ\\xadÙÙ' '<>?:\"{}|_+' '\\'\\'\\'\\'\"'\n",
      " \",./;'[]\\\\-=\" '() { 0; }; touch /tmp/blns.shellshock1.fail;'\n",
      " 'ì¬íê³¼íì ì´íì°êµ¬ì' 'testâ\\xa0testâ«'\n",
      " '0ï¸â£ 1ï¸â£ 2ï¸â£ 3ï¸â£ 4ï¸â£ 5ï¸â£ 6ï¸â£ 7ï¸â£ 8ï¸â£ 9ï¸â£ ð' 100\n",
      " '!@#$%^&*()' \"'\"\n",
      " 'Ì¦HÍÌ¬Ì¤ÌÌ¤eÍ ÍÌÌ¥ÌÌ»ÍÌwÌhÌÌ¯ÍoÌÍÌÍÌ±Ì® ÒÌºÌÌÌÍWÌ·Ì¼Ì\\xadaÌºÌªÍiÌ¨ÍÍÌ\\xadÍÌ¯ÌtÌ¶Ì¼Ì®sÌÌÍÍ Ì\\xa0Ì«Ì\\xa0BÌ»ÍÍÍÍÌ³eÌµhÌµÌ¬ÍÌ«ÍiÌÌ¹ÍÌ³Ì³Ì®ÍÌ«nÍdÌ´ÌªÌÌ ÍÌ°ÍÌ©ÍÍÍÌ²TÍ¢ÍÌ¼ÍÌªhÍÍÌ®Ì»eÌ¬ÌÍÌ Ì¤Ì¹ÌWÍÍÍÌÌÍÍaÍÍÍÌ¹Ì¼'\n",
      " '../../../../../../../../../../../etc/passwd%00' 'åè£½æ¼¢èª'\n",
      " '`ââ¬â¹âºï¬ï¬â¡Â°Â·ââÂ±' 'ãã¼ãã£ã¼ã¸è¡ããªãã' 1 -0.5\n",
      " 'ZÌ®ÌÍÌ\\xa0ÍÍAÌ¥ÌÌÍÌ»ÌLÌ£ÍÍÌ¯Ì¹ÌÍGÌ»OÌ\\xadÌÌ®' 'ã' '1;DROP TABLE users'\n",
      " -1 'á' '(ï¾à²¥çà²¥ï¼ï¾ï»¿ â»ââ»' '00ËÆ$-' '1/0' 'ï½ï½¨(Â´âï½â©'\n",
      " \"<svg><script>0<1>alert('XSS')</script>\" 'âââ' 'ã»(ï¿£âï¿£)ã»:*:'\n",
      " ',ãã»:*:ã»ãâ( â» Ï â» )ãã»:*:ã»ãâ' 'â¢' 'ç°ä¸\\xadããã«ããã¦ä¸ãã'\n",
      " '__ï¾(,_,*)' 'Ù¡Ù¢Ù£'\n",
      " 'Ø«Ù ÙÙØ³ Ø³ÙØ·Øª ÙØ¨Ø§ÙØªØ\\xadØ¯ÙØ¯Ø, Ø¬Ø²ÙØ±ØªÙ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù Ø£Ù Ø¯ÙÙ. Ø¥Ø° ÙÙØ§Ø Ø§ÙØ³ØªØ§Ø± ÙØªÙØµÙØ¨ ÙØ§Ù. Ø£ÙÙÙ Ø§ÙØ·Ø§ÙÙØ§Ø Ø¨Ø±ÙØ·Ø§ÙÙØ§-ÙØ±ÙØ³Ø§ ÙØ¯ Ø£Ø®Ø°. Ø³ÙÙÙØ§ÙØ Ø¥ØªÙØ§ÙÙØ© Ø¨ÙÙ ÙØ§, ÙØ°ÙØ± Ø'\n",
      " 'ð¾ ð ð ð ð ð ð ð§' \"<img src=x onerror=alert('hi') />\"\n",
      " 'ã½à¼¼àºÙÍàºà¼½ï¾ ã½à¼¼àºÙÍàºà¼½ï¾' 'âð¿ ðªð¿ ðð¿ ðð¿ ðð¿ ðð¿'\n",
      " 'TÌÌ\\xadÌºÌºoÍ Ì·iÌ²Ì¬ÍÌªÍnÌÌÍvÍÌÌÌÌ¦oÌ¶ÌÌ°Ì\\xa0keÍÍÌ®ÌºÌªÌ¹Ì±Ì¤ ÌtÍÌÍÌ³Ì£Ì»ÌªhÌ¼ÍÌ²Ì¦Ì³ÌÌ²eÍÌ£Ì°Ì¦Ì¬Í Ì¢Ì¼Ì»Ì±ÌhÍÍÍÍÌÌ£Ì²iÌ¦Ì²Ì£Ì°Ì¤vÌ»ÍeÌºÌ\\xadÌ³ÌªÌ°-mÌ¢iÍnÌÌºÌÌ²Ì¯Ì°dÌµÌ¼ÌÍÌ©Ì¼ÌÌ³ ÌÌ¥Ì±Ì³Ì\\xadrÌÌÌeÍpÍ\\xa0rÌ¼ÌÌ»Ì\\xadÌeÍÌºÌ\\xa0Ì£sÌ'\n",
      " 'ÃÃÃÃËÃÃï£¿ÃÃÃâ' '(ï½¡â â âï½¡)' 'é¨è½æ\\xa0¼'\n",
      " \"ËÉnbá´lÉ ÉuÆÉÉ¯ ÇÉ¹olop ÊÇ ÇÉ¹oqÉl Ên Êunpá´pá´Éuá´ É¹odÉ¯ÇÊ poÉ¯sná´Ç op pÇs 'Êá´lÇ Æuá´Ésá´dá´pÉ É¹nÊÇÊÉÇsuoÉ 'ÊÇÉ¯É Êá´s É¹olop É¯nsdá´ É¯ÇÉ¹oË¥\"\n",
      " 'á\\xa0'\n",
      " '×Ö¼Ö°×¨Öµ××©×Ö´××ª, ×Ö¼Ö¸×¨Ö¸× ×Ö±×Ö¹×Ö´××, ×Öµ×ª ×Ö·×©Ö¼×Ö¸×Ö·×Ö´×, ×Ö°×Öµ×ª ×Ö¸×Ö¸×¨Ö¶×¥'\n",
      " 'Â¡â¢Â£Â¢âÂ§Â¶â¢ÂªÂºââ\\xa0' '/dev/null; touch /tmp/blns.fail ; echo'\n",
      " \"1'; DROP TABLE users--\" 'ð¾ ð ð ð ð ð ð ð'\n",
      " 'Ì¡ÍÍÌIÍÌÌÌ¦nÍÍÍvÌ®Ì«okÌ²Ì«ÌÍiÌÍÌ\\xadÌ¹Ì\\xa0ÌnÌ¡Ì»Ì®Ì£ÌºgÌ²ÍÍÌ\\xadÍÌ¬Í Ì°tÍÌ¦hÌÌ²eÌ¢Ì¤ ÍÌ¬Ì²ÍfÌ´ÌÍÌ£eÍÍeÌ£Ì¥Ì©lÍÍÍiÍ\\xa0ÍÍÌ¦nÍÍÌÍÌ³Ì®gÍ Ì¨oÍ¡ÍÌªfÌÌ£Ì¬ ÌÌÍÌÍÌ®cÒÍÌ«ÍÍÍÍÍhÌµÌ¤Ì£ÍÍaÍÌÌ¼ÍÍoÌ¼Ì£Ì¥sÍ¢Ì±ÍÌºÌÌ¦Ì».ÌÌ'\n",
      " 'â' 'Â¸ËÃâÄ±ËÃÂ¯ËÂ¿' 'ì¸ëë°í\\xa0ë¥´'\n",
      " 'ÌÌºÍÌ¹Ì¯ÍTÌ±Ì¤ÍÌ¥ÍÍhÍÌ²eÍÍÌ¼ÌÌÌ¼Ì£Í ÍÌÌ±Ì\\xa0ÍÍÍNÍ\\xa0ÍeÌÌ±zÌÌÌÌºÍpÌ¤ÌºÌ¹ÍÌ¯ÍeÍÌ\\xa0Ì»Ì\\xa0rÌ¨Ì¤ÍÌºÌÍÌÌdÍÌ\\xa0ÌÌ\\xadÌ¬ÌiÌ¦ÍÌ©ÍÍÌ¤aÌ\\xa0ÌÌ¬ÍÌnÍÍ Ì»ÌÌ°ÍÍhÌµÍiÌ³ÌvÌ¢ÍeÍÌ\\xadÍ-ÒÌ\\xadÌ©Ì¼ÍmÌ¤Ì\\xadÌ«iÍÍÌÌ¦nÌÍdÌ£Ì ÍÌ¯Ì²ÍoÌ¨ÌÌ¯Ì°Ì²'\n",
      " 0 'â©testâ©' 'â£' 'Ã¥ÃâÆÂ©ËâËÂ¬â¦Ã¦' 'ç¤¾æç§å\\xad¸é¢èªå\\xad¸ç\\xa0ç©¶æ'\n",
      " 'âªâªtestâª' 'ï»¿' 'â¤ï¸ ð ð ð ð ð ð ð ð ð ð ð ð ð ð' 'â«testâ«'\n",
      " 'â¦testâ§' '\\'\"\\'\\'\\'\\'\"' 'â¡'\n",
      " 'ð\\xa0ð\\xa0±ð\\xa0¹ð\\xa0±ð\\xa0±¸ð\\xa0²ð\\xa0³']\n",
      "*******\n",
      "owns_car:\n",
      "['Yes' 'No']\n",
      "*******\n"
     ]
    }
   ],
   "source": [
    "for col in cat_col:\n",
    "    print(f\"{col}:\")\n",
    "    print(demographic_data[col].unique())\n",
    "    print(\"*******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_data.drop('default', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                               Non-Null Count  Dtype         \n",
      "---  ------                               --------------  -----         \n",
      " 0   customer_id                          4000 non-null   int64         \n",
      " 1   first_name                           4000 non-null   object        \n",
      " 2   last_name                            4000 non-null   object        \n",
      " 3   gender                               4000 non-null   object        \n",
      " 4   past_3_years_bike_related_purchases  4000 non-null   int64         \n",
      " 5   DOB                                  4000 non-null   datetime64[ns]\n",
      " 6   job_title                            4000 non-null   object        \n",
      " 7   job_industry_category                4000 non-null   object        \n",
      " 8   wealth_segment                       4000 non-null   object        \n",
      " 9   deceased_indicator                   4000 non-null   object        \n",
      " 10  owns_car                             4000 non-null   object        \n",
      " 11  tenure                               4000 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(8)\n",
      "memory usage: 375.1+ KB\n"
     ]
    }
   ],
   "source": [
    "demographic_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a new 'Age' feature, we will convert the 'DOB' (Date of Birth) column into an `Age` column. Once this transformation is complete, we will drop the 'DOB' column from the dataset. \n",
    "This process involves replacing the date of birth values with the corresponding ages, and after successfully creating the new 'Age' feature, we remove the original 'DOB' column to keep our dataset more organized and concise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "def from_dob_to_age(born):\n",
    "    # Get today's date\n",
    "    today = dt.date.today()\n",
    "    \n",
    "    # Calculate the age by subtracting the birth year\n",
    "    age = today.year - born.year\n",
    "    \n",
    "    # Adjust the age if the birthdate hasn't occurred in the current year\n",
    "    if (today.month, today.day) < (born.month, born.day):\n",
    "        age -= 1\n",
    "    \n",
    "    return age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the function on the DOB column\n",
    "demographic_data['Age'] = demographic_data['DOB'].apply(lambda x: from_dob_to_age(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_data.drop('DOB',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   customer_id                          4000 non-null   int64  \n",
      " 1   first_name                           4000 non-null   object \n",
      " 2   last_name                            4000 non-null   object \n",
      " 3   gender                               4000 non-null   object \n",
      " 4   past_3_years_bike_related_purchases  4000 non-null   int64  \n",
      " 5   job_title                            4000 non-null   object \n",
      " 6   job_industry_category                4000 non-null   object \n",
      " 7   wealth_segment                       4000 non-null   object \n",
      " 8   deceased_indicator                   4000 non-null   object \n",
      " 9   owns_car                             4000 non-null   object \n",
      " 10  tenure                               4000 non-null   float64\n",
      " 11  Age                                  4000 non-null   int64  \n",
      "dtypes: float64(1), int64(3), object(8)\n",
      "memory usage: 375.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Print the information of our dataset\n",
    "demographic_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>past_3_years_bike_related_purchases</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_industry_category</th>\n",
       "      <th>wealth_segment</th>\n",
       "      <th>deceased_indicator</th>\n",
       "      <th>owns_car</th>\n",
       "      <th>tenure</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Laraine</td>\n",
       "      <td>Medendorp</td>\n",
       "      <td>Female</td>\n",
       "      <td>93</td>\n",
       "      <td>Executive Secretary</td>\n",
       "      <td>Health</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Eli</td>\n",
       "      <td>Bockman</td>\n",
       "      <td>Male</td>\n",
       "      <td>81</td>\n",
       "      <td>Administrative Officer</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>16.0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Arlin</td>\n",
       "      <td>Dearle</td>\n",
       "      <td>Male</td>\n",
       "      <td>61</td>\n",
       "      <td>Recruiting Manager</td>\n",
       "      <td>Property</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>15.0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Talbot</td>\n",
       "      <td>Pristnor</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>Business Systems Development Analyst</td>\n",
       "      <td>IT</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>No</td>\n",
       "      <td>7.0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Sheila-kathryn</td>\n",
       "      <td>Calton</td>\n",
       "      <td>Female</td>\n",
       "      <td>56</td>\n",
       "      <td>Senior Editor</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Affluent Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>8.0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id      first_name  last_name  gender  \\\n",
       "0            1         Laraine  Medendorp  Female   \n",
       "1            2             Eli    Bockman    Male   \n",
       "2            3           Arlin     Dearle    Male   \n",
       "3            4          Talbot   Pristnor    Male   \n",
       "4            5  Sheila-kathryn     Calton  Female   \n",
       "\n",
       "   past_3_years_bike_related_purchases                             job_title  \\\n",
       "0                                   93                   Executive Secretary   \n",
       "1                                   81                Administrative Officer   \n",
       "2                                   61                    Recruiting Manager   \n",
       "3                                   33  Business Systems Development Analyst   \n",
       "4                                   56                         Senior Editor   \n",
       "\n",
       "  job_industry_category     wealth_segment deceased_indicator owns_car  \\\n",
       "0                Health      Mass Customer                  N      Yes   \n",
       "1    Financial Services      Mass Customer                  N      Yes   \n",
       "2              Property      Mass Customer                  N      Yes   \n",
       "3                    IT      Mass Customer                  N       No   \n",
       "4         Manufacturing  Affluent Customer                  N      Yes   \n",
       "\n",
       "   tenure  Age  \n",
       "0    11.0   70  \n",
       "1    16.0   42  \n",
       "2    15.0   69  \n",
       "3     7.0   62  \n",
       "4     8.0   46  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the head of the dataset\n",
    "demographic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transaction Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   transaction_id           20000 non-null  int64         \n",
      " 1   product_id               20000 non-null  int64         \n",
      " 2   customer_id              20000 non-null  int64         \n",
      " 3   transaction_date         20000 non-null  datetime64[ns]\n",
      " 4   online_order             19640 non-null  float64       \n",
      " 5   order_status             20000 non-null  object        \n",
      " 6   brand                    19803 non-null  object        \n",
      " 7   product_line             19803 non-null  object        \n",
      " 8   product_class            19803 non-null  object        \n",
      " 9   product_size             19803 non-null  object        \n",
      " 10  list_price               20000 non-null  float64       \n",
      " 11  standard_cost            19803 non-null  float64       \n",
      " 12  product_first_sold_date  19803 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(3), object(5)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "transaction_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Missing Values in Demographic Dataset************\n",
      "transaction_id               0\n",
      "product_id                   0\n",
      "customer_id                  0\n",
      "transaction_date             0\n",
      "online_order               360\n",
      "order_status                 0\n",
      "brand                      197\n",
      "product_line               197\n",
      "product_class              197\n",
      "product_size               197\n",
      "list_price                   0\n",
      "standard_cost              197\n",
      "product_first_sold_date    197\n",
      "dtype: int64\n",
      "\n",
      "Percentage of Missing Values:\n",
      "transaction_id             0.000\n",
      "product_id                 0.000\n",
      "customer_id                0.000\n",
      "transaction_date           0.000\n",
      "online_order               1.800\n",
      "order_status               0.000\n",
      "brand                      0.985\n",
      "product_line               0.985\n",
      "product_class              0.985\n",
      "product_size               0.985\n",
      "list_price                 0.000\n",
      "standard_cost              0.985\n",
      "product_first_sold_date    0.985\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in key columns\n",
    "missing_values = transaction_data.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of missing values in each column\n",
    "total_records = transaction_data.shape[0]\n",
    "percentage_missing = (missing_values / total_records) * 100\n",
    "\n",
    "# Print results\n",
    "print(np.char.center('Missing Values in Demographic Dataset', 60, '*'))\n",
    "print(missing_values)\n",
    "print(\"\\nPercentage of Missing Values:\")\n",
    "print(percentage_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the online order column with the mode value \n",
    "transaction_data['online_order'] = transaction_data['online_order'].fillna(transaction_data['online_order'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Online Order:` Since 'online_order' has only 1.8% missing values, it's a small proportion of the data. We can safely fill these missing values with the mode, which is the most frequent data point. Filling with the mode ensures that you don't lose important data while addressing the missing values.\n",
    "\n",
    "`Brand`, `Product Line`, `Product Class`, `Product Size`, `Standard Cost`, and `Product First Sold Date`: These columns all have a 1% rate of missing values, and they seem to follow the same missing data pattern. In this case, it is reasonable to remove the rows containing these null values. The missing data accounts for only a small fraction of the dataset (1%), and removing them won't significantly impact your analysis or modeling process. This approach helps maintain data quality and consistency in the remaining dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing other data rows with nul values\n",
    "transaction_data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Missing Values in Demographic Dataset************\n",
      "transaction_id             0\n",
      "product_id                 0\n",
      "customer_id                0\n",
      "transaction_date           0\n",
      "online_order               0\n",
      "order_status               0\n",
      "brand                      0\n",
      "product_line               0\n",
      "product_class              0\n",
      "product_size               0\n",
      "list_price                 0\n",
      "standard_cost              0\n",
      "product_first_sold_date    0\n",
      "dtype: int64\n",
      "\n",
      "Percentage of Missing Values:\n",
      "transaction_id             0.0\n",
      "product_id                 0.0\n",
      "customer_id                0.0\n",
      "transaction_date           0.0\n",
      "online_order               0.0\n",
      "order_status               0.0\n",
      "brand                      0.0\n",
      "product_line               0.0\n",
      "product_class              0.0\n",
      "product_size               0.0\n",
      "list_price                 0.0\n",
      "standard_cost              0.0\n",
      "product_first_sold_date    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in key columns\n",
    "missing_values = transaction_data.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of missing values in each column\n",
    "total_records = transaction_data.shape[0]\n",
    "percentage_missing = (missing_values / total_records) * 100\n",
    "\n",
    "# Print results\n",
    "print(np.char.center('Missing Values in Demographic Dataset', 60, '*'))\n",
    "print(missing_values)\n",
    "print(\"\\nPercentage of Missing Values:\")\n",
    "print(percentage_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting datatypes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'list_price' column to a numeric data type\n",
    "transaction_data['list_price'] = pd.to_numeric(transaction_data['list_price'])\n",
    "\n",
    "# Convert 'standard_cost' column to a numeric data type\n",
    "transaction_data['standard_cost'] = pd.to_numeric(transaction_data['standard_cost'])\n",
    "\n",
    "# Convert 'transaction_date' column to a datetime data type\n",
    "transaction_data['transaction_date'] = pd.to_datetime(transaction_data['transaction_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19803 entries, 0 to 19999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   transaction_id           19803 non-null  int64         \n",
      " 1   product_id               19803 non-null  int64         \n",
      " 2   customer_id              19803 non-null  int64         \n",
      " 3   transaction_date         19803 non-null  datetime64[ns]\n",
      " 4   online_order             19803 non-null  float64       \n",
      " 5   order_status             19803 non-null  object        \n",
      " 6   brand                    19803 non-null  object        \n",
      " 7   product_line             19803 non-null  object        \n",
      " 8   product_class            19803 non-null  object        \n",
      " 9   product_size             19803 non-null  object        \n",
      " 10  list_price               19803 non-null  float64       \n",
      " 11  standard_cost            19803 non-null  float64       \n",
      " 12  product_first_sold_date  19803 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(3), object(5)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Print out the dataset information\n",
    "transaction_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate rows found in the transaction_data dataset.\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows in the transaction_data dataset\n",
    "duplicates = transaction_data[transaction_data.duplicated()]\n",
    "\n",
    "# Count the number of duplicate rows\n",
    "num_duplicates = len(duplicates)\n",
    "\n",
    "# Display the duplicate rows and the total count\n",
    "if num_duplicates > 0:\n",
    "    print(f\"Number of duplicate rows: {num_duplicates}\")\n",
    "    print(\"Duplicate rows:\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"No duplicate rows found in the transaction_data dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure the consistency and quality of the categorical data in the dataset, we will create a list that includes all the categorical columns. Categorical columns are those that contain non-numeric data, such as labels, categories, or text values. This list will help us focus on examining and potentially cleaning these specific columns to maintain data integrity and accuracy during our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['order_status', 'brand', 'product_line', 'product_class', 'product_size']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect the categorical columns into a list\n",
    "cat_col = transaction_data.select_dtypes(include='object').columns.tolist()\n",
    "cat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: order_status\n",
      "Unique Values:\n",
      "['Approved' 'Cancelled']\n",
      "Duplicate values found in this column.\n",
      "\n",
      "*******\n",
      "\n",
      "Column: brand\n",
      "Unique Values:\n",
      "['Solex' 'Trek Bicycles' 'OHM Cycles' 'Norco Bicycles' 'Giant Bicycles'\n",
      " 'WeareA2B']\n",
      "Duplicate values found in this column.\n",
      "\n",
      "*******\n",
      "\n",
      "Column: product_line\n",
      "Unique Values:\n",
      "['Standard' 'Road' 'Mountain' 'Touring']\n",
      "Duplicate values found in this column.\n",
      "\n",
      "*******\n",
      "\n",
      "Column: product_class\n",
      "Unique Values:\n",
      "['medium' 'low' 'high']\n",
      "Duplicate values found in this column.\n",
      "\n",
      "*******\n",
      "\n",
      "Column: product_size\n",
      "Unique Values:\n",
      "['medium' 'large' 'small']\n",
      "Duplicate values found in this column.\n",
      "\n",
      "*******\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each categorical column in the dataset\n",
    "for col in cat_col:\n",
    "    # Print the column name\n",
    "    print(f\"Column: {col}\")\n",
    "    \n",
    "    # Check for unique values in the column\n",
    "    unique_values = transaction_data[col].unique()\n",
    "    \n",
    "    # Print the unique values\n",
    "    print(\"Unique Values:\")\n",
    "    print(unique_values)\n",
    "    \n",
    "    # Check for duplicate values in the column\n",
    "    is_duplicate = transaction_data[col].duplicated().any()\n",
    "    \n",
    "    # Print the duplicate status\n",
    "    if is_duplicate:\n",
    "        print(\"Duplicate values found in this column.\")\n",
    "    else:\n",
    "        print(\"No duplicate values found in this column.\")\n",
    "    \n",
    "    # Add a separator for clarity\n",
    "    print(\"\\n*******\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the `product_first_sold_date` column may have an incorrect date format that needs to be corrected. To address this issue, we'll convert the data in this column to the correct datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'product_first_sold_date' column to object (string) data type\n",
    "transaction_data['product_first_sold_date'] = transaction_data['product_first_sold_date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19803 entries, 0 to 19999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   transaction_id           19803 non-null  int64         \n",
      " 1   product_id               19803 non-null  int64         \n",
      " 2   customer_id              19803 non-null  int64         \n",
      " 3   transaction_date         19803 non-null  datetime64[ns]\n",
      " 4   online_order             19803 non-null  float64       \n",
      " 5   order_status             19803 non-null  object        \n",
      " 6   brand                    19803 non-null  object        \n",
      " 7   product_line             19803 non-null  object        \n",
      " 8   product_class            19803 non-null  object        \n",
      " 9   product_size             19803 non-null  object        \n",
      " 10  list_price               19803 non-null  float64       \n",
      " 11  standard_cost            19803 non-null  float64       \n",
      " 12  product_first_sold_date  19803 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(3), int64(3), object(6)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "transaction_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'product_first_sold_date' column to datetime with year, month, and date\n",
    "transaction_data['product_first_sold_date'] = pd.to_datetime(transaction_data['product_first_sold_date'], unit='s').dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>online_order</th>\n",
       "      <th>order_status</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_line</th>\n",
       "      <th>product_class</th>\n",
       "      <th>product_size</th>\n",
       "      <th>list_price</th>\n",
       "      <th>standard_cost</th>\n",
       "      <th>product_first_sold_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2950</td>\n",
       "      <td>2017-02-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Solex</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>71.49</td>\n",
       "      <td>53.62</td>\n",
       "      <td>1970-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3120</td>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Trek Bicycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>large</td>\n",
       "      <td>2091.47</td>\n",
       "      <td>388.92</td>\n",
       "      <td>1970-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>402</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>OHM Cycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>1793.43</td>\n",
       "      <td>248.82</td>\n",
       "      <td>1970-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>3135</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Norco Bicycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>1198.46</td>\n",
       "      <td>381.10</td>\n",
       "      <td>1970-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>787</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Giant Bicycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>large</td>\n",
       "      <td>1765.30</td>\n",
       "      <td>709.48</td>\n",
       "      <td>1970-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id  product_id  customer_id transaction_date  online_order  \\\n",
       "0               1           2         2950       2017-02-25           0.0   \n",
       "1               2           3         3120       2017-05-21           1.0   \n",
       "2               3          37          402       2017-10-16           0.0   \n",
       "3               4          88         3135       2017-08-31           0.0   \n",
       "4               5          78          787       2017-10-01           1.0   \n",
       "\n",
       "  order_status           brand product_line product_class product_size  \\\n",
       "0     Approved           Solex     Standard        medium       medium   \n",
       "1     Approved   Trek Bicycles     Standard        medium        large   \n",
       "2     Approved      OHM Cycles     Standard           low       medium   \n",
       "3     Approved  Norco Bicycles     Standard        medium       medium   \n",
       "4     Approved  Giant Bicycles     Standard        medium        large   \n",
       "\n",
       "   list_price  standard_cost product_first_sold_date  \n",
       "0       71.49          53.62              1970-01-01  \n",
       "1     2091.47         388.92              1970-01-01  \n",
       "2     1793.43         248.82              1970-01-01  \n",
       "3     1198.46         381.10              1970-01-01  \n",
       "4     1765.30         709.48              1970-01-01  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "transaction_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>online_order</th>\n",
       "      <th>order_status</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_line</th>\n",
       "      <th>product_class</th>\n",
       "      <th>product_size</th>\n",
       "      <th>list_price</th>\n",
       "      <th>standard_cost</th>\n",
       "      <th>product_first_sold_date</th>\n",
       "      <th>Transaction_year</th>\n",
       "      <th>Transaction_month</th>\n",
       "      <th>Transaction_day</th>\n",
       "      <th>day_of_the_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2950</td>\n",
       "      <td>2017-02-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Solex</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>71.49</td>\n",
       "      <td>53.62</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>February</td>\n",
       "      <td>25</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3120</td>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Trek Bicycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>large</td>\n",
       "      <td>2091.47</td>\n",
       "      <td>388.92</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>May</td>\n",
       "      <td>21</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>402</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>OHM Cycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>1793.43</td>\n",
       "      <td>248.82</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>October</td>\n",
       "      <td>16</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>3135</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Norco Bicycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>1198.46</td>\n",
       "      <td>381.10</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>August</td>\n",
       "      <td>31</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>787</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Giant Bicycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>large</td>\n",
       "      <td>1765.30</td>\n",
       "      <td>709.48</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>October</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id  product_id  customer_id transaction_date  online_order  \\\n",
       "0               1           2         2950       2017-02-25           0.0   \n",
       "1               2           3         3120       2017-05-21           1.0   \n",
       "2               3          37          402       2017-10-16           0.0   \n",
       "3               4          88         3135       2017-08-31           0.0   \n",
       "4               5          78          787       2017-10-01           1.0   \n",
       "\n",
       "  order_status           brand product_line product_class product_size  \\\n",
       "0     Approved           Solex     Standard        medium       medium   \n",
       "1     Approved   Trek Bicycles     Standard        medium        large   \n",
       "2     Approved      OHM Cycles     Standard           low       medium   \n",
       "3     Approved  Norco Bicycles     Standard        medium       medium   \n",
       "4     Approved  Giant Bicycles     Standard        medium        large   \n",
       "\n",
       "   list_price  standard_cost product_first_sold_date Transaction_year  \\\n",
       "0       71.49          53.62              1970-01-01             2017   \n",
       "1     2091.47         388.92              1970-01-01             2017   \n",
       "2     1793.43         248.82              1970-01-01             2017   \n",
       "3     1198.46         381.10              1970-01-01             2017   \n",
       "4     1765.30         709.48              1970-01-01             2017   \n",
       "\n",
       "  Transaction_month Transaction_day day_of_the_week  \n",
       "0          February              25        Saturday  \n",
       "1               May              21          Sunday  \n",
       "2           October              16          Monday  \n",
       "3            August              31        Thursday  \n",
       "4           October               1          Sunday  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create new variables based on 'transaction_date'\n",
    "transaction_data['Transaction_year'] = transaction_data['transaction_date'].dt.year\n",
    "transaction_data['Transaction_month'] = transaction_data['transaction_date'].dt.month_name()\n",
    "transaction_data['Transaction_day'] = transaction_data['transaction_date'].dt.day\n",
    "transaction_data['day_of_the_week'] = transaction_data['transaction_date'].dt.day_name()\n",
    "\n",
    "# Convert the 'Transaction_year' and 'Transaction_day' columns to string data type\n",
    "transaction_data['Transaction_year'] = transaction_data['Transaction_year'].astype(str)\n",
    "transaction_data['Transaction_day'] = transaction_data['Transaction_day'].astype(str)\n",
    "\n",
    "# Display the first few rows of the updated dataset\n",
    "transaction_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the three datasets are interconnected, with the first one containing transaction information, the second one containing demographic data, and the third one containing customer addresses, we can establish relationships between them. We can use the 'customer_id' as a common key to link these datasets.\n",
    "\n",
    "By performing an inner join, we combine these datasets based on the 'customer_id,' which acts as a primary key in the first dataset (transactions) and a foreign key in the second (demographics) and third (addresses) datasets. This process creates a unified dataset that contains transaction details along with corresponding demographic and address information for each customer. It allows us to analyze and draw insights from a comprehensive dataset that combines information from different sourc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>online_order</th>\n",
       "      <th>order_status</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_line</th>\n",
       "      <th>product_class</th>\n",
       "      <th>product_size</th>\n",
       "      <th>...</th>\n",
       "      <th>last_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>past_3_years_bike_related_purchases</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_industry_category</th>\n",
       "      <th>wealth_segment</th>\n",
       "      <th>deceased_indicator</th>\n",
       "      <th>owns_car</th>\n",
       "      <th>tenure</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2950</td>\n",
       "      <td>2017-02-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Solex</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>...</td>\n",
       "      <td>Anthony</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>Software Engineer I</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10.0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11065</td>\n",
       "      <td>1</td>\n",
       "      <td>2950</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Giant Bicycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>...</td>\n",
       "      <td>Anthony</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>Software Engineer I</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10.0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18923</td>\n",
       "      <td>62</td>\n",
       "      <td>2950</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Solex</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>...</td>\n",
       "      <td>Anthony</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>Software Engineer I</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10.0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3120</td>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Trek Bicycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>large</td>\n",
       "      <td>...</td>\n",
       "      <td>O'Donnell</td>\n",
       "      <td>Female</td>\n",
       "      <td>89</td>\n",
       "      <td>Clinical Specialist</td>\n",
       "      <td>Health</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10.0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6862</td>\n",
       "      <td>4</td>\n",
       "      <td>3120</td>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Giant Bicycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "      <td>...</td>\n",
       "      <td>O'Donnell</td>\n",
       "      <td>Female</td>\n",
       "      <td>89</td>\n",
       "      <td>Clinical Specialist</td>\n",
       "      <td>Health</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10.0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id  product_id  customer_id transaction_date  online_order  \\\n",
       "0               1           2         2950       2017-02-25           0.0   \n",
       "1           11065           1         2950       2017-10-16           0.0   \n",
       "2           18923          62         2950       2017-04-26           0.0   \n",
       "3               2           3         3120       2017-05-21           1.0   \n",
       "4            6862           4         3120       2017-10-05           0.0   \n",
       "\n",
       "  order_status           brand product_line product_class product_size  ...  \\\n",
       "0     Approved           Solex     Standard        medium       medium  ...   \n",
       "1     Approved  Giant Bicycles     Standard        medium       medium  ...   \n",
       "2     Approved           Solex     Standard        medium       medium  ...   \n",
       "3     Approved   Trek Bicycles     Standard        medium        large  ...   \n",
       "4     Approved  Giant Bicycles     Standard          high       medium  ...   \n",
       "\n",
       "   last_name  gender past_3_years_bike_related_purchases            job_title  \\\n",
       "0    Anthony    Male                                  19  Software Engineer I   \n",
       "1    Anthony    Male                                  19  Software Engineer I   \n",
       "2    Anthony    Male                                  19  Software Engineer I   \n",
       "3  O'Donnell  Female                                  89  Clinical Specialist   \n",
       "4  O'Donnell  Female                                  89  Clinical Specialist   \n",
       "\n",
       "  job_industry_category wealth_segment deceased_indicator owns_car tenure Age  \n",
       "0    Financial Services  Mass Customer                  N      Yes   10.0  68  \n",
       "1    Financial Services  Mass Customer                  N      Yes   10.0  68  \n",
       "2    Financial Services  Mass Customer                  N      Yes   10.0  68  \n",
       "3                Health  Mass Customer                  N      Yes   10.0  44  \n",
       "4                Health  Mass Customer                  N      Yes   10.0  44  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining the Transactions dataset with the Customer Demographics dataset using 'customer_id' as the common key.\n",
    "# We perform an inner join to keep only the rows with matching customer IDs in both datasets.\n",
    "transactions_demographics = transaction_data.merge(demographic_data, on='customer_id', how='inner')\n",
    "\n",
    "# Display the first 5 rows of the merged dataset to inspect the result.\n",
    "transactions_demographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the Transactions and Customer Demographics dataset with the Addresses dataset into a final_dataset dataset (Customers, Transactions, Addresses).\n",
    "# We use 'customer_id' as the common key for the merge and perform an inner join to retain rows with matching customer IDs in all three datasets.\n",
    "final_data = transactions_demographics.merge(customer_data, on='customer_id', how='inner')\n",
    "\n",
    "# The resulting final dataset now contains information about customers, their transactions, and their addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19773 entries, 0 to 19772\n",
      "Data columns (total 32 columns):\n",
      " #   Column                               Non-Null Count  Dtype         \n",
      "---  ------                               --------------  -----         \n",
      " 0   transaction_id                       19773 non-null  int64         \n",
      " 1   product_id                           19773 non-null  int64         \n",
      " 2   customer_id                          19773 non-null  int64         \n",
      " 3   transaction_date                     19773 non-null  datetime64[ns]\n",
      " 4   online_order                         19773 non-null  float64       \n",
      " 5   order_status                         19773 non-null  object        \n",
      " 6   brand                                19773 non-null  object        \n",
      " 7   product_line                         19773 non-null  object        \n",
      " 8   product_class                        19773 non-null  object        \n",
      " 9   product_size                         19773 non-null  object        \n",
      " 10  list_price                           19773 non-null  float64       \n",
      " 11  standard_cost                        19773 non-null  float64       \n",
      " 12  product_first_sold_date              19773 non-null  object        \n",
      " 13  Transaction_year                     19773 non-null  object        \n",
      " 14  Transaction_month                    19773 non-null  object        \n",
      " 15  Transaction_day                      19773 non-null  object        \n",
      " 16  day_of_the_week                      19773 non-null  object        \n",
      " 17  first_name                           19773 non-null  object        \n",
      " 18  last_name                            19773 non-null  object        \n",
      " 19  gender                               19773 non-null  object        \n",
      " 20  past_3_years_bike_related_purchases  19773 non-null  int64         \n",
      " 21  job_title                            19773 non-null  object        \n",
      " 22  job_industry_category                19773 non-null  object        \n",
      " 23  wealth_segment                       19773 non-null  object        \n",
      " 24  deceased_indicator                   19773 non-null  object        \n",
      " 25  owns_car                             19773 non-null  object        \n",
      " 26  tenure                               19773 non-null  float64       \n",
      " 27  Age                                  19773 non-null  int64         \n",
      " 28  address                              19773 non-null  object        \n",
      " 29  postcode                             19773 non-null  int64         \n",
      " 30  state                                19773 non-null  object        \n",
      " 31  property_valuation                   19773 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(4), int64(7), object(20)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# print the information of the dataset\n",
    "final_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the final_data as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final CTA dataset has been saved to 'final_cta_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Define the file path where you want to save the final CTA dataset.\n",
    "output_file_path = 'final_cta_data.csv'\n",
    "\n",
    "# Save the CTA dataset to a CSV file.\n",
    "final_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display a message indicating that the dataset has been saved.\n",
    "print(f\"The final CTA dataset has been saved to '{output_file_path}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
