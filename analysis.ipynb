{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Replace 'your_file.xlsx' with the actual file path\n",
    "file_path = 'data/kpmg.xlsx'\n",
    "\n",
    "# Use the ExcelFile class to read the Excel file\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# List the sheet names in the Excel file\n",
    "sheet_names = xls.sheet_names\n",
    "\n",
    "# Create DataFrames for each sheet\n",
    "dataframes = {}  # Dictionary to store DataFrames\n",
    "\n",
    "for sheet_name in sheet_names:\n",
    "    dataframes[sheet_name] = pd.read_excel(xls, sheet_name)\n",
    "\n",
    "# Now you have separate DataFrames for each sheet\n",
    "# access the dataframes using their sheet names\n",
    "customer_data = dataframes['Transactions']\n",
    "demographic_data = dataframes['CustomerDemographic']\n",
    "transaction_data = dataframes['CustomerAddress']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>online_order</th>\n",
       "      <th>order_status</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_line</th>\n",
       "      <th>product_class</th>\n",
       "      <th>product_size</th>\n",
       "      <th>list_price</th>\n",
       "      <th>standard_cost</th>\n",
       "      <th>product_first_sold_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2950</td>\n",
       "      <td>2017-02-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Solex</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>71.49</td>\n",
       "      <td>53.62</td>\n",
       "      <td>41245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3120</td>\n",
       "      <td>2017-05-21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Trek Bicycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>large</td>\n",
       "      <td>2091.47</td>\n",
       "      <td>388.92</td>\n",
       "      <td>41701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>402</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>OHM Cycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>1793.43</td>\n",
       "      <td>248.82</td>\n",
       "      <td>36361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>3135</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Norco Bicycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>1198.46</td>\n",
       "      <td>381.10</td>\n",
       "      <td>36145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>787</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Giant Bicycles</td>\n",
       "      <td>Standard</td>\n",
       "      <td>medium</td>\n",
       "      <td>large</td>\n",
       "      <td>1765.30</td>\n",
       "      <td>709.48</td>\n",
       "      <td>42226.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id  product_id  customer_id transaction_date  online_order  \\\n",
       "0               1           2         2950       2017-02-25           0.0   \n",
       "1               2           3         3120       2017-05-21           1.0   \n",
       "2               3          37          402       2017-10-16           0.0   \n",
       "3               4          88         3135       2017-08-31           0.0   \n",
       "4               5          78          787       2017-10-01           1.0   \n",
       "\n",
       "  order_status           brand product_line product_class product_size  \\\n",
       "0     Approved           Solex     Standard        medium       medium   \n",
       "1     Approved   Trek Bicycles     Standard        medium        large   \n",
       "2     Approved      OHM Cycles     Standard           low       medium   \n",
       "3     Approved  Norco Bicycles     Standard        medium       medium   \n",
       "4     Approved  Giant Bicycles     Standard        medium        large   \n",
       "\n",
       "   list_price  standard_cost  product_first_sold_date  \n",
       "0       71.49          53.62                  41245.0  \n",
       "1     2091.47         388.92                  41701.0  \n",
       "2     1793.43         248.82                  36361.0  \n",
       "3     1198.46         381.10                  36145.0  \n",
       "4     1765.30         709.48                  42226.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the first five rows of the customer dataset\n",
    "customer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>past_3_years_bike_related_purchases</th>\n",
       "      <th>DOB</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_industry_category</th>\n",
       "      <th>wealth_segment</th>\n",
       "      <th>deceased_indicator</th>\n",
       "      <th>default</th>\n",
       "      <th>owns_car</th>\n",
       "      <th>tenure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Laraine</td>\n",
       "      <td>Medendorp</td>\n",
       "      <td>F</td>\n",
       "      <td>93</td>\n",
       "      <td>1953-10-12</td>\n",
       "      <td>Executive Secretary</td>\n",
       "      <td>Health</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>\"'</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Eli</td>\n",
       "      <td>Bockman</td>\n",
       "      <td>Male</td>\n",
       "      <td>81</td>\n",
       "      <td>1980-12-16</td>\n",
       "      <td>Administrative Officer</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>&lt;script&gt;alert('hi')&lt;/script&gt;</td>\n",
       "      <td>Yes</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Arlin</td>\n",
       "      <td>Dearle</td>\n",
       "      <td>Male</td>\n",
       "      <td>61</td>\n",
       "      <td>1954-01-20</td>\n",
       "      <td>Recruiting Manager</td>\n",
       "      <td>Property</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>2018-02-01 00:00:00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Talbot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>1961-10-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IT</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>() { _; } &gt;_[$($())] { touch /tmp/blns.shellsh...</td>\n",
       "      <td>No</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Sheila-kathryn</td>\n",
       "      <td>Calton</td>\n",
       "      <td>Female</td>\n",
       "      <td>56</td>\n",
       "      <td>1977-05-13</td>\n",
       "      <td>Senior Editor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Affluent Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>NIL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id      first_name  last_name  gender  \\\n",
       "0            1         Laraine  Medendorp       F   \n",
       "1            2             Eli    Bockman    Male   \n",
       "2            3           Arlin     Dearle    Male   \n",
       "3            4          Talbot        NaN    Male   \n",
       "4            5  Sheila-kathryn     Calton  Female   \n",
       "\n",
       "   past_3_years_bike_related_purchases        DOB               job_title  \\\n",
       "0                                   93 1953-10-12     Executive Secretary   \n",
       "1                                   81 1980-12-16  Administrative Officer   \n",
       "2                                   61 1954-01-20      Recruiting Manager   \n",
       "3                                   33 1961-10-03                     NaN   \n",
       "4                                   56 1977-05-13           Senior Editor   \n",
       "\n",
       "  job_industry_category     wealth_segment deceased_indicator  \\\n",
       "0                Health      Mass Customer                  N   \n",
       "1    Financial Services      Mass Customer                  N   \n",
       "2              Property      Mass Customer                  N   \n",
       "3                    IT      Mass Customer                  N   \n",
       "4                   NaN  Affluent Customer                  N   \n",
       "\n",
       "                                             default owns_car  tenure  \n",
       "0                                                 \"'      Yes    11.0  \n",
       "1                       <script>alert('hi')</script>      Yes    16.0  \n",
       "2                                2018-02-01 00:00:00      Yes    15.0  \n",
       "3  () { _; } >_[$($())] { touch /tmp/blns.shellsh...       No     7.0  \n",
       "4                                                NIL      Yes     8.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the first five rows of the demographic dataset\n",
    "demographic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Gender Values:\n",
      "['F' 'Male' 'Female' 'U' 'Femal' 'M']\n",
      "\n",
      "Gender Value Counts:\n",
      "Female    2037\n",
      "Male      1872\n",
      "U           88\n",
      "F            1\n",
      "Femal        1\n",
      "M            1\n",
      "Name: gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get unique values in the 'gender' column and count the occurrences of each unique value\n",
    "gender_counts = demographic_data['gender'].unique()\n",
    "counts = demographic_data['gender'].value_counts()\n",
    "\n",
    "# Print the unique values and their respective counts\n",
    "print(\"Unique Gender Values:\")\n",
    "print(gender_counts)\n",
    "print(\"\\nGender Value Counts:\")\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Gender Values (Corrected):\n",
      "['Female' 'Male' 'Unspecified']\n",
      "\n",
      "Gender Value Counts (Corrected):\n",
      "Female         2039\n",
      "Male           1873\n",
      "Unspecified      88\n",
      "Name: gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping dictionary to standardize gender values\n",
    "gender_mapping = {\n",
    "    'F': 'Female',\n",
    "    'Male': 'Male',\n",
    "    'Female': 'Female',\n",
    "    'U': 'Unspecified',\n",
    "    'Femal': 'Female',\n",
    "    'M': 'Male'\n",
    "}\n",
    "\n",
    "# Use the mapping dictionary to replace gender values\n",
    "demographic_data['gender'] = demographic_data['gender'].replace(gender_mapping)\n",
    "\n",
    "# Check the corrected unique values and their counts\n",
    "gender_counts_corrected = demographic_data['gender'].unique()\n",
    "counts_corrected = demographic_data['gender'].value_counts()\n",
    "\n",
    "# Print the corrected unique values and their counts\n",
    "print(\"Unique Gender Values (Corrected):\")\n",
    "print(gender_counts_corrected)\n",
    "print(\"\\nGender Value Counts (Corrected):\")\n",
    "print(counts_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>address</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>property_valuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>060 Morning Avenue</td>\n",
       "      <td>2016</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6 Meadow Vale Court</td>\n",
       "      <td>2153</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0 Holy Cross Court</td>\n",
       "      <td>4211</td>\n",
       "      <td>QLD</td>\n",
       "      <td>Australia</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>17979 Del Mar Point</td>\n",
       "      <td>2448</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>9 Oakridge Court</td>\n",
       "      <td>3216</td>\n",
       "      <td>VIC</td>\n",
       "      <td>Australia</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id              address  postcode            state    country  \\\n",
       "0            1   060 Morning Avenue      2016  New South Wales  Australia   \n",
       "1            2  6 Meadow Vale Court      2153  New South Wales  Australia   \n",
       "2            4   0 Holy Cross Court      4211              QLD  Australia   \n",
       "3            5  17979 Del Mar Point      2448  New South Wales  Australia   \n",
       "4            6     9 Oakridge Court      3216              VIC  Australia   \n",
       "\n",
       "   property_valuation  \n",
       "0                  10  \n",
       "1                  10  \n",
       "2                   9  \n",
       "3                   4  \n",
       "4                   9  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the first five rows of the transaction dataset\n",
    "transaction_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy and Completeness Assessment\n",
    "\n",
    "***Check for data accuracy issues, such as missing values in critical columns.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transaction Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3999 entries, 0 to 3998\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   customer_id         3999 non-null   int64 \n",
      " 1   address             3999 non-null   object\n",
      " 2   postcode            3999 non-null   int64 \n",
      " 3   state               3999 non-null   object\n",
      " 4   country             3999 non-null   object\n",
      " 5   property_valuation  3999 non-null   int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 187.6+ KB\n"
     ]
    }
   ],
   "source": [
    "transaction_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Missing Values in Transaction Dataset************\n",
      "customer_id           0\n",
      "address               0\n",
      "postcode              0\n",
      "state                 0\n",
      "country               0\n",
      "property_valuation    0\n",
      "dtype: int64\n",
      "\n",
      "Percentage of Missing Values:\n",
      "customer_id           0.0\n",
      "address               0.0\n",
      "postcode              0.0\n",
      "state                 0.0\n",
      "country               0.0\n",
      "property_valuation    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Assessment\n",
    "import numpy as np\n",
    "# Check for missing values in key columns\n",
    "missing_values = transaction_data.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of missing values in each column\n",
    "total_records = transaction_data.shape[0]\n",
    "percentage_missing = (missing_values / total_records) * 100\n",
    "\n",
    "# Print results\n",
    "print(np.char.center('Missing Values in Transaction Dataset', 60, '*'))\n",
    "print(missing_values)\n",
    "print(\"\\nPercentage of Missing Values:\")\n",
    "print(percentage_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3999.000000\n",
       "mean        7.514379\n",
       "std         2.824663\n",
       "min         1.000000\n",
       "25%         6.000000\n",
       "50%         8.000000\n",
       "75%        10.000000\n",
       "max        12.000000\n",
       "Name: property_valuation, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_data['property_valuation'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows in Transaction Dataset:\n",
      "Empty DataFrame\n",
      "Columns: [customer_id, address, postcode, state, country, property_valuation]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "duplicate_rows = transaction_data[transaction_data.duplicated()]\n",
    "# Print duplicate rows, if any\n",
    "print(\"Duplicate Rows in Transaction Dataset:\")\n",
    "print(duplicate_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demographic_data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                               Non-Null Count  Dtype         \n",
      "---  ------                               --------------  -----         \n",
      " 0   customer_id                          4000 non-null   int64         \n",
      " 1   first_name                           4000 non-null   object        \n",
      " 2   last_name                            3875 non-null   object        \n",
      " 3   gender                               4000 non-null   object        \n",
      " 4   past_3_years_bike_related_purchases  4000 non-null   int64         \n",
      " 5   DOB                                  3913 non-null   datetime64[ns]\n",
      " 6   job_title                            3494 non-null   object        \n",
      " 7   job_industry_category                3344 non-null   object        \n",
      " 8   wealth_segment                       4000 non-null   object        \n",
      " 9   deceased_indicator                   4000 non-null   object        \n",
      " 10  default                              3698 non-null   object        \n",
      " 11  owns_car                             4000 non-null   object        \n",
      " 12  tenure                               3913 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(9)\n",
      "memory usage: 406.4+ KB\n"
     ]
    }
   ],
   "source": [
    "demographic_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Missing Values in Demographic Dataset************\n",
      "customer_id                              0\n",
      "first_name                               0\n",
      "last_name                              125\n",
      "gender                                   0\n",
      "past_3_years_bike_related_purchases      0\n",
      "DOB                                     87\n",
      "job_title                              506\n",
      "job_industry_category                  656\n",
      "wealth_segment                           0\n",
      "deceased_indicator                       0\n",
      "default                                302\n",
      "owns_car                                 0\n",
      "tenure                                  87\n",
      "dtype: int64\n",
      "\n",
      "Percentage of Missing Values:\n",
      "customer_id                             0.000\n",
      "first_name                              0.000\n",
      "last_name                               3.125\n",
      "gender                                  0.000\n",
      "past_3_years_bike_related_purchases     0.000\n",
      "DOB                                     2.175\n",
      "job_title                              12.650\n",
      "job_industry_category                  16.400\n",
      "wealth_segment                          0.000\n",
      "deceased_indicator                      0.000\n",
      "default                                 7.550\n",
      "owns_car                                0.000\n",
      "tenure                                  2.175\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in key columns\n",
    "missing_values = demographic_data.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of missing values in each column\n",
    "total_records = demographic_data.shape[0]\n",
    "percentage_missing = (missing_values / total_records) * 100\n",
    "\n",
    "# Print results\n",
    "print(np.char.center('Missing Values in Demographic Dataset', 60, '*'))\n",
    "print(missing_values)\n",
    "print(\"\\nPercentage of Missing Values:\")\n",
    "print(percentage_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Customer Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   transaction_id           20000 non-null  int64         \n",
      " 1   product_id               20000 non-null  int64         \n",
      " 2   customer_id              20000 non-null  int64         \n",
      " 3   transaction_date         20000 non-null  datetime64[ns]\n",
      " 4   online_order             19640 non-null  float64       \n",
      " 5   order_status             20000 non-null  object        \n",
      " 6   brand                    19803 non-null  object        \n",
      " 7   product_line             19803 non-null  object        \n",
      " 8   product_class            19803 non-null  object        \n",
      " 9   product_size             19803 non-null  object        \n",
      " 10  list_price               20000 non-null  float64       \n",
      " 11  standard_cost            19803 non-null  float64       \n",
      " 12  product_first_sold_date  19803 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(3), object(5)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "customer_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Missing Values in Demographic Dataset************\n",
      "transaction_id               0\n",
      "product_id                   0\n",
      "customer_id                  0\n",
      "transaction_date             0\n",
      "online_order               360\n",
      "order_status                 0\n",
      "brand                      197\n",
      "product_line               197\n",
      "product_class              197\n",
      "product_size               197\n",
      "list_price                   0\n",
      "standard_cost              197\n",
      "product_first_sold_date    197\n",
      "dtype: int64\n",
      "\n",
      "Percentage of Missing Values:\n",
      "transaction_id             0.000\n",
      "product_id                 0.000\n",
      "customer_id                0.000\n",
      "transaction_date           0.000\n",
      "online_order               1.800\n",
      "order_status               0.000\n",
      "brand                      0.985\n",
      "product_line               0.985\n",
      "product_class              0.985\n",
      "product_size               0.985\n",
      "list_price                 0.000\n",
      "standard_cost              0.985\n",
      "product_first_sold_date    0.985\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in key columns\n",
    "missing_values = customer_data.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of missing values in each column\n",
    "total_records = customer_data.shape[0]\n",
    "percentage_missing = (missing_values / total_records) * 100\n",
    "\n",
    "# Print results\n",
    "print(np.char.center('Missing Values in Demographic Dataset', 60, '*'))\n",
    "print(missing_values)\n",
    "print(\"\\nPercentage of Missing Values:\")\n",
    "print(percentage_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all the missing values are less than 5 percent for all the columns we will drop all the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic Dataset After Dropping Missing Values:\n",
      "       transaction_id  product_id  customer_id transaction_date  online_order  \\\n",
      "0                   1           2         2950       2017-02-25           0.0   \n",
      "1                   2           3         3120       2017-05-21           1.0   \n",
      "2                   3          37          402       2017-10-16           0.0   \n",
      "3                   4          88         3135       2017-08-31           0.0   \n",
      "4                   5          78          787       2017-10-01           1.0   \n",
      "...               ...         ...          ...              ...           ...   \n",
      "19995           19996          51         1018       2017-06-24           1.0   \n",
      "19996           19997          41          127       2017-11-09           1.0   \n",
      "19997           19998          87         2284       2017-04-14           1.0   \n",
      "19998           19999           6         2764       2017-07-03           0.0   \n",
      "19999           20000          11         1144       2017-09-22           1.0   \n",
      "\n",
      "      order_status           brand product_line product_class product_size  \\\n",
      "0         Approved           Solex     Standard        medium       medium   \n",
      "1         Approved   Trek Bicycles     Standard        medium        large   \n",
      "2         Approved      OHM Cycles     Standard           low       medium   \n",
      "3         Approved  Norco Bicycles     Standard        medium       medium   \n",
      "4         Approved  Giant Bicycles     Standard        medium        large   \n",
      "...            ...             ...          ...           ...          ...   \n",
      "19995     Approved      OHM Cycles     Standard          high       medium   \n",
      "19996     Approved           Solex         Road        medium       medium   \n",
      "19997     Approved      OHM Cycles     Standard        medium       medium   \n",
      "19998     Approved      OHM Cycles     Standard          high       medium   \n",
      "19999     Approved   Trek Bicycles     Standard        medium        small   \n",
      "\n",
      "       list_price  standard_cost  product_first_sold_date  \n",
      "0           71.49          53.62                  41245.0  \n",
      "1         2091.47         388.92                  41701.0  \n",
      "2         1793.43         248.82                  36361.0  \n",
      "3         1198.46         381.10                  36145.0  \n",
      "4         1765.30         709.48                  42226.0  \n",
      "...           ...            ...                      ...  \n",
      "19995     2005.66        1203.40                  37823.0  \n",
      "19996      416.98         312.74                  35560.0  \n",
      "19997     1636.90          44.71                  40410.0  \n",
      "19998      227.88         136.73                  38216.0  \n",
      "19999     1775.81        1580.47                  36334.0  \n",
      "\n",
      "[19445 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values from the Demographic Dataset\n",
    "customer_data_cleaned = customer_data.dropna()\n",
    "\n",
    "# Verify that missing rows have been removed\n",
    "print(\"Demographic Dataset After Dropping Missing Values:\")\n",
    "print(customer_data_cleaned)\n",
    "\n",
    "# You can also reset the index if you want continuous index values\n",
    "customer_data_cleaned.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Missing Values in Demographic Dataset************\n",
      "transaction_id             0\n",
      "product_id                 0\n",
      "customer_id                0\n",
      "transaction_date           0\n",
      "online_order               0\n",
      "order_status               0\n",
      "brand                      0\n",
      "product_line               0\n",
      "product_class              0\n",
      "product_size               0\n",
      "list_price                 0\n",
      "standard_cost              0\n",
      "product_first_sold_date    0\n",
      "dtype: int64\n",
      "\n",
      "Percentage of Missing Values:\n",
      "transaction_id             0.0\n",
      "product_id                 0.0\n",
      "customer_id                0.0\n",
      "transaction_date           0.0\n",
      "online_order               0.0\n",
      "order_status               0.0\n",
      "brand                      0.0\n",
      "product_line               0.0\n",
      "product_class              0.0\n",
      "product_size               0.0\n",
      "list_price                 0.0\n",
      "standard_cost              0.0\n",
      "product_first_sold_date    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in key columns\n",
    "missing_values = customer_data_cleaned.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of missing values in each column\n",
    "total_records = customer_data_cleaned.shape[0]\n",
    "percentage_missing = (missing_values / total_records) * 100\n",
    "\n",
    "# Print results\n",
    "print(np.char.center('Missing Values in Demographic Dataset', 60, '*'))\n",
    "print(missing_values)\n",
    "print(\"\\nPercentage of Missing Values:\")\n",
    "print(percentage_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19445 entries, 0 to 19444\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   transaction_id           19445 non-null  int64         \n",
      " 1   product_id               19445 non-null  int64         \n",
      " 2   customer_id              19445 non-null  int64         \n",
      " 3   transaction_date         19445 non-null  datetime64[ns]\n",
      " 4   online_order             19445 non-null  float64       \n",
      " 5   order_status             19445 non-null  object        \n",
      " 6   brand                    19445 non-null  object        \n",
      " 7   product_line             19445 non-null  object        \n",
      " 8   product_class            19445 non-null  object        \n",
      " 9   product_size             19445 non-null  object        \n",
      " 10  list_price               19445 non-null  float64       \n",
      " 11  standard_cost            19445 non-null  float64       \n",
      " 12  product_first_sold_date  19445 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(3), object(5)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "customer_data_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows in Transaction Dataset:\n",
      "Empty DataFrame\n",
      "Columns: [transaction_id, product_id, customer_id, transaction_date, online_order, order_status, brand, product_line, product_class, product_size, list_price, standard_cost, product_first_sold_date]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows in the Transaction Dataset\n",
    "duplicate_rows= customer_data_cleaned[customer_data_cleaned.duplicated()]\n",
    "\n",
    "# Print duplicate rows, if any\n",
    "print(\"Duplicate Rows in Transaction Dataset:\")\n",
    "print(duplicate_rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
